{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of data types, \"ordered\" data refers to ordinal data.\n",
    "Ordinal data is a type of categorical data with an order (or rank).\n",
    "The order of these values is significant and typically represents some sort of hierarchy.\n",
    "For example, ratings data (like \"poor\", \"average\", \"good\", \"excellent\") is ordinal\n",
    "because there is a clear order to the categories.\n",
    "\n",
    "\n",
    "1. **age** - Real\n",
    "2. **sex** - Binary\n",
    "3. **cp** - Chest pain type (4 values) - Nominal\n",
    "4. **trestbps** - Resting blood age - Real\n",
    "5. **chol** - Serum cholesterol (in mg/dl) - Real\n",
    "6. **fbs** - Fasting blood sugar > 120 mg/dl - Binary\n",
    "7. **restecg** - Resting electrocardiographic results (values 0,1,2) - Nominal\n",
    "8. **thalach** - Maximum heart rate achieved - Real\n",
    "9. **exang** - Exercise induced angina - Binary\n",
    "10. **oldpeak** - Oldpeak = ST depression induced by exercise relative to rest - Real\n",
    "11. **slope** - The slope of the peak exercise ST segment - Ordered\n",
    "12. **ca** - Number of major vessels (0-3) colored by flouroscopy - Real\n",
    "13. **thal** - Thal: 3 = normal; 6 = fixed defect; 7 = reversable defect - Nominal\n",
    "14. **target**: 1 = no disease; 2 = presence of disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "detail = {\"age\": \"Age\", \"sex\": \"Sex\", \"cp\": \"Chest Pain Type\", \"trestbps\": \"Resting Blood Pressure\",\n",
    "          \"chol\": \"Serum Cholesterol\", \"fbs\": \"Fasting Blood Sugar\", \"restecg\": \"Resting ECG\",\n",
    "          \"thalach\": \"Max Heart Rate\", \"exang\": \"Exercise Induced Angina\", \"oldpeak\": \"Oldpeak\",\n",
    "          \"slope\": \"Slope\", \"ca\": \"Number of major vessels\", \"thal\": \"Thal\", \"target\": \"(0 - no disease, 1 - disease))\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2      3      4    5    6      7    8    9    10   11   12  13\n",
      "0  70.0  1.0  4.0  130.0  322.0  0.0  2.0  109.0  0.0  2.4  2.0  3.0  3.0   2\n",
      "1  67.0  0.0  3.0  115.0  564.0  0.0  2.0  160.0  0.0  1.6  2.0  0.0  7.0   1\n",
      "2  57.0  1.0  2.0  124.0  261.0  0.0  0.0  141.0  0.0  0.3  1.0  0.0  7.0   2\n",
      "3  64.0  1.0  4.0  128.0  263.0  0.0  0.0  105.0  1.0  0.2  2.0  1.0  7.0   1\n",
      "4  74.0  0.0  2.0  120.0  269.0  0.0  2.0  121.0  1.0  0.2  1.0  1.0  3.0   1\n",
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  70.0  1.0  4.0     130.0  322.0  0.0      2.0    109.0    0.0      2.4   \n",
      "1  67.0  0.0  3.0     115.0  564.0  0.0      2.0    160.0    0.0      1.6   \n",
      "2  57.0  1.0  2.0     124.0  261.0  0.0      0.0    141.0    0.0      0.3   \n",
      "3  64.0  1.0  4.0     128.0  263.0  0.0      0.0    105.0    1.0      0.2   \n",
      "4  74.0  0.0  2.0     120.0  269.0  0.0      2.0    121.0    1.0      0.2   \n",
      "\n",
      "   slope   ca  thal  target  \n",
      "0    2.0  3.0   3.0       2  \n",
      "1    2.0  0.0   7.0       1  \n",
      "2    1.0  0.0   7.0       2  \n",
      "3    2.0  1.0   7.0       1  \n",
      "4    1.0  1.0   3.0       1  \n",
      "Number of missing values: 0\n",
      "Number of duplicates: 0\n",
      "Number of features:  13\n",
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  70.0  1.0  4.0     130.0  322.0  0.0      2.0    109.0    0.0      2.4   \n",
      "1  67.0  0.0  3.0     115.0  564.0  0.0      2.0    160.0    0.0      1.6   \n",
      "2  57.0  1.0  2.0     124.0  261.0  0.0      0.0    141.0    0.0      0.3   \n",
      "3  64.0  1.0  4.0     128.0  263.0  0.0      0.0    105.0    1.0      0.2   \n",
      "4  74.0  0.0  2.0     120.0  269.0  0.0      2.0    121.0    1.0      0.2   \n",
      "\n",
      "   slope   ca  thal  \n",
      "0    2.0  3.0   3.0  \n",
      "1    2.0  0.0   7.0  \n",
      "2    1.0  0.0   7.0  \n",
      "3    2.0  1.0   7.0  \n",
      "4    1.0  1.0   3.0  \n"
     ]
    }
   ],
   "source": [
    "sns.set_theme(context=\"paper\", font_scale=1.5, style=\"whitegrid\", palette=\"Set2\")\n",
    "\n",
    "data = pd.read_csv(\"heart.dat\", sep=\"\\\\s+\", header=None)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "data.columns = detail.keys()\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum().sum()\n",
    "print(\"Number of missing values:\", missing_values)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "print(\"Number of duplicates:\", duplicates)\n",
    "\n",
    "noFeatures = data.shape[1]-1\n",
    "print(\"Number of features: \", noFeatures)\n",
    "\n",
    "numericalFeatures = (\"age\", \"sex\", \"trestbps\", \"chol\", \"fbs\", \"thalach\", \"exang\", \"oldpeak\", \"ca\")\n",
    "categoricalFeatures = (\"cp\", \"restecg\", \"slope\", \"thal\")\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "Y = data.iloc[:, -1]\n",
    "\n",
    "\n",
    "one_hot_X = pd.get_dummies(X, columns = [\"cp\", \"restecg\", \"slope\", \"thal\"])\n",
    "\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "realFeatures = (\"trestbps\", \"chol\", \"thalach\", \"oldpeak\")\n",
    "# considering ca ordered as only has 4 values\n",
    "categoricalFeatures = (\"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\", \"ca\")\n",
    "extraFeatures = (\"age\", \"sex\", \"target\")\n",
    "\n",
    "# Age vs. All Real for both Sexes\n",
    "for feature in data.columns:\n",
    "    if feature in realFeatures:\n",
    "        plt.figure()\n",
    "        sns.relplot(    \n",
    "                data=data, x=\"age\", y=feature, col=\"sex\",\n",
    "                hue=\"target\"\n",
    "        )\n",
    "        plt.savefig(f\"plots/{feature}_vs_age.png\")\n",
    "\n",
    "# Categorical Counts\n",
    "for feature in data.columns:\n",
    "    if feature in categoricalFeatures:\n",
    "        plt.figure()\n",
    "        sns.countplot(  # histplot if for continuous non categorical data\n",
    "            data=data, x=feature, hue=\"target\"\n",
    "        )\n",
    "        plt.title(f\"{detail[feature]} {detail['target']}\")\n",
    "        plt.savefig(f\"plots/{feature}_count.png\")\n",
    "\n",
    "# Categorical Normalized Counts\n",
    "# for feature in data.columns:\n",
    "#     if feature in categoricalFeatures:\n",
    "#         # thanks copilot\n",
    "#         proportions = data.groupby(feature)[\"target\"].value_counts(normalize=True).rename(\"proportion\").reset_index()\n",
    "\n",
    "#         plt.figure()\n",
    "#         sns.barplot(data=proportions, x=feature, y=\"proportion\", hue=\"target\")\n",
    "#         plt.title(f\"{detail[feature]} {detail['target']}\")\n",
    "#         plt.show()\n",
    "\n",
    "# for feature in data.columns[:-1]:\n",
    "#     plotter2v2(data, feature, \"target\")\n",
    "\n",
    "# normalizer = StandardScaler()\n",
    "# calculate and remove mean and standard deviation from the data\n",
    "# data_scaled = pd.DataFrame(normalizer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "\n",
    "\n",
    "# print(data.head())\n",
    "# sns.heatmap(data_scaled.corr(), annot=True, linewidths=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Table:\n",
      "   Iteration  Accuracy  Precision    Recall  F1 Score\n",
      "0          1  0.740741   0.766667  0.766667  0.766667\n",
      "1          2  0.870370   0.875000  0.903226  0.888889\n",
      "2          3  0.796296   0.888889  0.750000  0.813559\n",
      "3          4  0.759259   0.800000  0.774194  0.786885\n",
      "4          5  0.740741   0.687500  0.846154  0.758621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create empty lists to store the evaluation metrics\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "\n",
    "for random_state in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)\n",
    "    # Perform further analysis or model training with the current split\n",
    "    # Create a Naive Bayes classifier\n",
    "    model = GaussianNB()\n",
    "\n",
    "    # Train the model using the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    # pos_label referes to the HD presence class (the positive class)\n",
    "    pos_label = 1\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label=pos_label)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=pos_label)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=pos_label)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Append the evaluation metrics to the respective lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    # Print the evaluation metrics for the current iteration\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(pd.DataFrame(cm, columns=[\"Predicted HD Absence\", \"Predicted HD Presence\"], index=[\"Actual HD Absence\", \"Actual HD Presence\"]))\n",
    "    # print()\n",
    "\n",
    "\n",
    "# Create a DataFrame to store the evaluation metrics for each iteration\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Iteration\": range(1, 6),\n",
    "    \"Accuracy\": accuracy_list,\n",
    "    \"Precision\": precision_list,\n",
    "    \"Recall\": recall_list,\n",
    "    \"F1 Score\": f1_list\n",
    "})\n",
    "\n",
    "# Print the metrics table\n",
    "print(\"Metrics Table:\")\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics Table:\n",
    "   Iteration  Accuracy  Precision    Recall  F1 Score\n",
    "0          1  0.740741   0.766667  0.766667  0.766667\n",
    "1          2  0.870370   0.875000  0.903226  0.888889\n",
    "2          3  0.796296   0.888889  0.750000  0.813559\n",
    "3          4  0.759259   0.800000  0.774194  0.786885\n",
    "4          5  0.740741   0.687500  0.846154  0.758621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create empty lists to store the evaluation metrics\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "\n",
    "for random_state in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)\n",
    "    # Perform further analysis or model training with the current split\n",
    "    # Create a Naive Bayes classifier\n",
    "    model = GaussianNB()\n",
    "\n",
    "    # Train the model using the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    # pos_label referes to the HD presence class (the positive class)\n",
    "    pos_label = 1\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label=pos_label)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=pos_label)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=pos_label)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Append the evaluation metrics to the respective lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    # Print the evaluation metrics for the current iteration\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(pd.DataFrame(cm, columns=[\"Predicted HD Absence\", \"Predicted HD Presence\"], index=[\"Actual HD Absence\", \"Actual HD Presence\"]))\n",
    "    # print()\n",
    "\n",
    "\n",
    "# Create a DataFrame to store the evaluation metrics for each iteration\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Iteration\": range(1, 6),\n",
    "    \"Accuracy\": accuracy_list,\n",
    "    \"Precision\": precision_list,\n",
    "    \"Recall\": recall_list,\n",
    "    \"F1 Score\": f1_list\n",
    "})\n",
    "\n",
    "# Print the metrics table\n",
    "print(\"Metrics Table:\")\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
