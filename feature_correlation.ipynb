{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of data types, \"ordered\" data refers to ordinal data.\n",
    "Ordinal data is a type of categorical data with an order (or rank).\n",
    "The order of these values is significant and typically represents some sort of hierarchy.\n",
    "For example, ratings data (like \"poor\", \"average\", \"good\", \"excellent\") is ordinal\n",
    "because there is a clear order to the categories.\n",
    "\n",
    "\n",
    "1. **age** - Real\n",
    "2. **sex** - Binary\n",
    "3. **cp** - Chest pain type (4 values) - Nominal\n",
    "4. **trestbps** - Resting blood age - Real\n",
    "5. **chol** - Serum cholesterol (in mg/dl) - Real\n",
    "6. **fbs** - Fasting blood sugar > 120 mg/dl - Binary\n",
    "7. **restecg** - Resting electrocardiographic results (values 0,1,2) - Nominal\n",
    "8. **thalach** - Maximum heart rate achieved - Real\n",
    "9. **exang** - Exercise induced angina - Binary\n",
    "10. **oldpeak** - Oldpeak = ST depression induced by exercise relative to rest - Real\n",
    "11. **slope** - The slope of the peak exercise ST segment - Ordered\n",
    "12. **ca** - Number of major vessels (0-3) colored by flouroscopy - Real\n",
    "13. **thal** - Thal: 3 = normal; 6 = fixed defect; 7 = reversable defect - Nominal\n",
    "14. **target**: 1 = no disease; 2 = presence of disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "detail = {\"age\": \"Age\", \"sex\": \"Sex\", \"cp\": \"Chest Pain Type\", \"trestbps\": \"Resting Blood Pressure\",\n",
    "          \"chol\": \"Serum Cholesterol\", \"fbs\": \"Fasting Blood Sugar\", \"restecg\": \"Resting ECG\",\n",
    "          \"thalach\": \"Max Heart Rate\", \"exang\": \"Exercise Induced Angina\", \"oldpeak\": \"Oldpeak\",\n",
    "          \"slope\": \"Slope\", \"ca\": \"Number of major vessels\", \"thal\": \"Thal\", \"target\": \"(0 - no disease, 1 - disease))\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0 \n",
      "\n",
      "Number of duplicates: 0 \n",
      "\n",
      "Number of features:  13 \n",
      "\n",
      "    age  trestbps   chol  thalach  oldpeak   ca\n",
      "0  70.0     130.0  322.0    109.0      2.4  3.0\n",
      "1  67.0     115.0  564.0    160.0      1.6  0.0\n",
      "2  57.0     124.0  261.0    141.0      0.3  0.0\n",
      "3  64.0     128.0  263.0    105.0      0.2  1.0\n",
      "4  74.0     120.0  269.0    121.0      0.2  1.0 \n",
      "\n",
      "        age  trestbps      chol   thalach   oldpeak        ca\n",
      "0  1.712094 -0.075410  1.402212 -1.759208  1.181012  2.472682\n",
      "1  1.382140 -0.916759  6.093004  0.446409  0.481153 -0.711535\n",
      "2  0.282294 -0.411950  0.219823 -0.375291 -0.656118 -0.711535\n",
      "3  1.052186 -0.187590  0.258589 -1.932198 -0.743600  0.349871\n",
      "4  2.152032 -0.636310  0.374890 -1.240239 -0.743600  0.349871 \n",
      "\n",
      "one hot     age  sex  trestbps   chol  fbs  thalach  exang  oldpeak   ca  cp_1.0  ...  \\\n",
      "0  70.0  1.0     130.0  322.0  0.0    109.0    0.0      2.4  3.0       0  ...   \n",
      "1  67.0  0.0     115.0  564.0  0.0    160.0    0.0      1.6  0.0       0  ...   \n",
      "2  57.0  1.0     124.0  261.0  0.0    141.0    0.0      0.3  0.0       0  ...   \n",
      "3  64.0  1.0     128.0  263.0  0.0    105.0    1.0      0.2  1.0       0  ...   \n",
      "4  74.0  0.0     120.0  269.0  0.0    121.0    1.0      0.2  1.0       0  ...   \n",
      "\n",
      "   cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  slope_1.0  slope_2.0  \\\n",
      "0       1            0            0            1          0          1   \n",
      "1       0            0            0            1          0          1   \n",
      "2       0            1            0            0          1          0   \n",
      "3       1            1            0            0          0          1   \n",
      "4       0            0            0            1          1          0   \n",
      "\n",
      "   slope_3.0  thal_3.0  thal_6.0  thal_7.0  \n",
      "0          0         1         0         0  \n",
      "1          0         0         0         1  \n",
      "2          0         0         0         1  \n",
      "3          0         0         0         1  \n",
      "4          0         1         0         0  \n",
      "\n",
      "[5 rows x 22 columns] \n",
      "\n",
      "one hot standard         age  sex  trestbps      chol  fbs   thalach  exang   oldpeak  \\\n",
      "0  1.712094  1.0 -0.075410  1.402212  0.0 -1.759208    0.0  1.181012   \n",
      "1  1.382140  0.0 -0.916759  6.093004  0.0  0.446409    0.0  0.481153   \n",
      "2  0.282294  1.0 -0.411950  0.219823  0.0 -0.375291    0.0 -0.656118   \n",
      "3  1.052186  1.0 -0.187590  0.258589  0.0 -1.932198    1.0 -0.743600   \n",
      "4  2.152032  0.0 -0.636310  0.374890  0.0 -1.240239    1.0 -0.743600   \n",
      "\n",
      "         ca  cp_1.0  ...  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0  2.472682       0  ...       1            0            0            1   \n",
      "1 -0.711535       0  ...       0            0            0            1   \n",
      "2 -0.711535       0  ...       0            1            0            0   \n",
      "3  0.349871       0  ...       1            1            0            0   \n",
      "4  0.349871       0  ...       0            0            0            1   \n",
      "\n",
      "   slope_1.0  slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  \n",
      "0          0          1          0         1         0         0  \n",
      "1          0          1          0         0         0         1  \n",
      "2          1          0          0         0         0         1  \n",
      "3          0          1          0         0         0         1  \n",
      "4          1          0          0         1         0         0  \n",
      "\n",
      "[5 rows x 22 columns] \n",
      "\n",
      "one hot norm         age  sex  trestbps      chol  fbs   thalach  exang   oldpeak  \\\n",
      "0  0.854167  1.0  0.339623  0.447489  0.0  0.290076    0.0  0.387097   \n",
      "1  0.791667  0.0  0.198113  1.000000  0.0  0.679389    0.0  0.258065   \n",
      "2  0.583333  1.0  0.283019  0.308219  0.0  0.534351    0.0  0.048387   \n",
      "3  0.729167  1.0  0.320755  0.312785  0.0  0.259542    1.0  0.032258   \n",
      "4  0.937500  0.0  0.245283  0.326484  0.0  0.381679    1.0  0.032258   \n",
      "\n",
      "         ca  cp_1.0  ...  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0  1.000000       0  ...       1            0            0            1   \n",
      "1  0.000000       0  ...       0            0            0            1   \n",
      "2  0.000000       0  ...       0            1            0            0   \n",
      "3  0.333333       0  ...       1            1            0            0   \n",
      "4  0.333333       0  ...       0            0            0            1   \n",
      "\n",
      "   slope_1.0  slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  \n",
      "0          0          1          0         1         0         0  \n",
      "1          0          1          0         0         0         1  \n",
      "2          1          0          0         0         0         1  \n",
      "3          0          1          0         0         0         1  \n",
      "4          1          0          0         1         0         0  \n",
      "\n",
      "[5 rows x 22 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "sns.set_theme(context=\"paper\", font_scale=1.5, style=\"whitegrid\", palette=\"Set2\")\n",
    "\n",
    "data = pd.read_csv(\"heart.dat\", sep=\"\\\\s+\", header=None)\n",
    "\n",
    "data.columns = detail.keys()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Number of missing values:\", data.isnull().sum().sum(), \"\\n\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"Number of duplicates:\", data.duplicated().sum(), \"\\n\")\n",
    "\n",
    "noFeatures = data.shape[1]-1\n",
    "print(\"Number of features: \", noFeatures, \"\\n\")\n",
    "\n",
    "continuousFeatures = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\", \"ca\"]\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "Y = data.iloc[:, -1]\n",
    "\n",
    "print(X[continuousFeatures].head(), \"\\n\")\n",
    "# Apply scaler only to continuous variables\n",
    "standardizedX = X.copy()\n",
    "standardizedX[continuousFeatures] = StandardScaler().fit_transform(X[continuousFeatures])\n",
    "\n",
    "normalizedX = X.copy()\n",
    "normalizedX[continuousFeatures] = MinMaxScaler().fit_transform(X[continuousFeatures])\n",
    "\n",
    "print(standardizedX[continuousFeatures].head(), \"\\n\")\n",
    "\n",
    "one_hot_X = pd.get_dummies(X, columns=[\"cp\", \"restecg\", \"slope\", \"thal\"])\n",
    "one_hot_standardizedX = pd.get_dummies(standardizedX, columns=[\"cp\", \"restecg\", \"slope\", \"thal\"])\n",
    "one_hot_normalizedX = pd.get_dummies(normalizedX, columns=[\"cp\", \"restecg\", \"slope\", \"thal\"])\n",
    "\n",
    "print(\"one hot\", one_hot_X.head(), \"\\n\")\n",
    "print(\"one hot standard\", one_hot_standardizedX.head(), \"\\n\")\n",
    "print(\"one hot norm\", one_hot_normalizedX.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realFeatures = (\"trestbps\", \"chol\", \"thalach\", \"oldpeak\")\n",
    "# considering ca ordered as only has 4 values\n",
    "categoricalFeatures = (\"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\", \"ca\")\n",
    "extraFeatures = (\"age\", \"sex\", \"target\")\n",
    "\n",
    "# Age vs. All Real for both Sexes\n",
    "for feature in data.columns:\n",
    "    if feature in realFeatures:\n",
    "        plt.figure()\n",
    "        sns.relplot(    \n",
    "                data=data, x=\"age\", y=feature, col=\"sex\",\n",
    "                hue=\"target\"\n",
    "        )\n",
    "        plt.savefig(f\"plots/{feature}_vs_age.png\")\n",
    "\n",
    "# Categorical Counts\n",
    "for feature in data.columns:\n",
    "    if feature in categoricalFeatures:\n",
    "        plt.figure()\n",
    "        sns.countplot(  # histplot if for continuous non categorical data\n",
    "            data=data, x=feature, hue=\"target\"\n",
    "        )\n",
    "        plt.title(f\"{detail[feature]} {detail['target']}\")\n",
    "        plt.savefig(f\"plots/{feature}_count.png\")\n",
    "\n",
    "# Categorical Normalized Counts\n",
    "# for feature in data.columns:\n",
    "#     if feature in categoricalFeatures:\n",
    "#         # thanks copilot\n",
    "#         proportions = data.groupby(feature)[\"target\"].value_counts(normalize=True).rename(\"proportion\").reset_index()\n",
    "\n",
    "#         plt.figure()\n",
    "#         sns.barplot(data=proportions, x=feature, y=\"proportion\", hue=\"target\")\n",
    "#         plt.title(f\"{detail[feature]} {detail['target']}\")\n",
    "#         plt.show()\n",
    "\n",
    "# for feature in data.columns[:-1]:\n",
    "#     plotter2v2(data, feature, \"target\")\n",
    "\n",
    "# normalizer = StandardScaler()\n",
    "# calculate and remove mean and standard deviation from the data\n",
    "# data_scaled = pd.DataFrame(normalizer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "\n",
    "\n",
    "# print(data.head())\n",
    "# sns.heatmap(data_scaled.corr(), annot=True, linewidths=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time  test_accuracy  test_precision  test_recall   test_f1  \\\n",
      "0  0.001998    0.008001       0.814815        0.833333     0.833333  0.833333   \n",
      "1  0.002998    0.007008       0.833333        0.838710     0.866667  0.852459   \n",
      "2  0.001999    0.006998       0.888889        0.875000     0.933333  0.903226   \n",
      "3  0.001998    0.005999       0.833333        0.838710     0.866667  0.852459   \n",
      "4  0.002002    0.009030       0.833333        0.838710     0.866667  0.852459   \n",
      "\n",
      "   test_neg_log_loss  \n",
      "0          -0.778455  \n",
      "1          -0.820856  \n",
      "2          -0.333911  \n",
      "3          -0.686468  \n",
      "4          -0.527435  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858787</td>\n",
       "      <td>-0.629425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.858787</td>\n",
       "      <td>-0.595637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.731426</td>\n",
       "      <td>-0.595094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_var_smoothing  mean_test_f1  mean_test_neg_log_loss\n",
       "0                 0.0      0.858787               -0.629425\n",
       "1             0.00001      0.858787               -0.595637\n",
       "2                 0.1      0.731426               -0.595094"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "nb_results = cross_validate(GaussianNB(), X, Y, cv=5, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"neg_log_loss\"])\n",
    "results_df = pd.DataFrame(nb_results)\n",
    "print(results_df)\n",
    "\n",
    "clf = GridSearchCV(GaussianNB(), {\"var_smoothing\": [1e-9, 1e-5, 1e-1]}, cv=5, scoring=[\"f1\", \"neg_log_loss\"], return_train_score=False, refit=False)\n",
    "clf.fit(X, Y)\n",
    "results_gs = pd.DataFrame(clf.cv_results_)\n",
    "results_gs[['param_var_smoothing', 'mean_test_f1', 'mean_test_neg_log_loss']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>100</td>\n",
       "      <td>0.866420</td>\n",
       "      <td>-0.407480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867823</td>\n",
       "      <td>-0.404644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>100</td>\n",
       "      <td>0.866314</td>\n",
       "      <td>-0.405866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sag</td>\n",
       "      <td>100</td>\n",
       "      <td>0.765340</td>\n",
       "      <td>-0.543240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saga</td>\n",
       "      <td>100</td>\n",
       "      <td>0.766901</td>\n",
       "      <td>-0.566636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.865091</td>\n",
       "      <td>-0.404979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.867823</td>\n",
       "      <td>-0.404644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.866314</td>\n",
       "      <td>-0.405866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sag</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.831881</td>\n",
       "      <td>-0.428492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saga</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.802997</td>\n",
       "      <td>-0.457572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.865091</td>\n",
       "      <td>-0.404979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.867823</td>\n",
       "      <td>-0.404644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.866314</td>\n",
       "      <td>-0.405866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sag</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.840050</td>\n",
       "      <td>-0.404812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>saga</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.839993</td>\n",
       "      <td>-0.421398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.865091</td>\n",
       "      <td>-0.404979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.867823</td>\n",
       "      <td>-0.404644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.866314</td>\n",
       "      <td>-0.405866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sag</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.852889</td>\n",
       "      <td>-0.398756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>saga</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.840050</td>\n",
       "      <td>-0.404865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_solver param_max_iter  mean_test_f1  mean_test_neg_log_loss\n",
       "0         lbfgs            100      0.866420               -0.407480\n",
       "1     newton-cg            100      0.867823               -0.404644\n",
       "2     liblinear            100      0.866314               -0.405866\n",
       "3           sag            100      0.765340               -0.543240\n",
       "4          saga            100      0.766901               -0.566636\n",
       "5         lbfgs           1000      0.865091               -0.404979\n",
       "6     newton-cg           1000      0.867823               -0.404644\n",
       "7     liblinear           1000      0.866314               -0.405866\n",
       "8           sag           1000      0.831881               -0.428492\n",
       "9          saga           1000      0.802997               -0.457572\n",
       "10        lbfgs           2500      0.865091               -0.404979\n",
       "11    newton-cg           2500      0.867823               -0.404644\n",
       "12    liblinear           2500      0.866314               -0.405866\n",
       "13          sag           2500      0.840050               -0.404812\n",
       "14         saga           2500      0.839993               -0.421398\n",
       "15        lbfgs           5000      0.865091               -0.404979\n",
       "16    newton-cg           5000      0.867823               -0.404644\n",
       "17    liblinear           5000      0.866314               -0.405866\n",
       "18          sag           5000      0.852889               -0.398756\n",
       "19         saga           5000      0.840050               -0.404865"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "\n",
    "\n",
    "# nb_results = cross_validate(LogisticRegression(), standardizedX, Y, cv=5, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"neg_log_loss\"])\n",
    "# results_df = pd.DataFrame(nb_results)\n",
    "# print(\"standardizedX\", \"\\n\", results_df.mean(), \"\\n\\n\")\n",
    "\n",
    "\n",
    "# nb_results = cross_validate(LogisticRegression(), normalizedX, Y, cv=5, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"neg_log_loss\"])\n",
    "# results_df = pd.DataFrame(nb_results)\n",
    "# print(\"normalizedX\",\"\\n\", results_df.mean(), \"\\n\\n\")\n",
    "\n",
    "# nb_results = cross_validate(LogisticRegression(), one_hot_standardizedX, Y, cv=5, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"neg_log_loss\"])\n",
    "# results_df = pd.DataFrame(nb_results)\n",
    "# print(\"one_hot_standardizedX\",\"\\n\", results_df.mean(), \"\\n\\n\")\n",
    "\n",
    "# nb_results = cross_validate(LogisticRegression(), one_hot_normalizedX, Y, cv=5, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"neg_log_loss\"])\n",
    "# results_df = pd.DataFrame(nb_results)\n",
    "# print(\"one_hot_normalizedX\",\"\\n\", results_df.mean(), \"\\n\\n\")\n",
    "\n",
    "param_grid = [    \n",
    "    {\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1, scoring=[\"f1\", \"neg_log_loss\"], return_train_score=False, refit=False)\n",
    "clf.fit(X, Y)\n",
    "results_gs = pd.DataFrame(clf.cv_results_)\n",
    "results_gs[['param_solver', 'param_max_iter', 'mean_test_f1', 'mean_test_neg_log_loss']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\romeu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.796048</td>\n",
       "      <td>-7.931206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.834426</td>\n",
       "      <td>-2.546506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.843147</td>\n",
       "      <td>-1.694138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.832644</td>\n",
       "      <td>-1.238183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>-0.881955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_neighbors  mean_test_f1  mean_test_neg_log_loss\n",
       "0                 1      0.796048               -7.931206\n",
       "1                 3      0.834426               -2.546506\n",
       "2                 5      0.843147               -1.694138\n",
       "3                 7      0.832644               -1.238183\n",
       "4                 9      0.823800               -0.881955"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), {\"n_neighbors\": [1, 3, 5, 7, 9]}, cv=5, scoring=[\"f1\", \"neg_log_loss\"], return_train_score=False, refit=False)\n",
    "clf.fit(one_hot_standardizedX, Y)\n",
    "results_gs = pd.DataFrame(clf.cv_results_)\n",
    "results_gs[['param_n_neighbors', 'mean_test_f1', 'mean_test_neg_log_loss']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
